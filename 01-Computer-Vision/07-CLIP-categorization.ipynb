{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image categorization with CLIP\n",
        "\n",
        "Created by [Artem Konevskikh](https://aiculedssul.net)"
      ],
      "metadata": {
        "id": "sNDknGKrnIJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install libraries\n",
        "!pip install ftfy\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aztWQ5jLn_MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import libraries\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import clip\n",
        "import torch\n",
        "import tqdm\n",
        "from PIL import Image"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a5mRwQpBSW1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load('ViT-B/32', device)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6I4FMxrKSgHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run\n",
        "# params\n",
        "#@markdown Path to the directory containing images\n",
        "img_dir = \"/content/images\" #@param {\"type\": \"string\"}\n",
        "#@markdown Categories, should be comma separated\n",
        "categories = \"a dog, a cat, a mushroom\" #@param {\"type\": \"string\"}\n",
        "\n",
        "# find all image files in the directory\n",
        "img_ext = ['tif', 'tiff', 'TIF', 'TIFF', 'png', 'PNG', 'jpg', 'jpeg', 'JPG', 'JPEG', 'bmp', 'BMP']\n",
        "images = []\n",
        "[images.extend(glob.glob(img_dir + '/*.' + e)) for e in img_ext]\n",
        "\n",
        "# split categories\n",
        "cats = [c.strip() for c in categories.split(\",\")]\n",
        "text_inputs = torch.cat([clip.tokenize(c) for c in cats]).to(device)\n",
        "result = []\n",
        "# process images\n",
        "for image_path in tqdm.tqdm(images):\n",
        "  # read image\n",
        "  image = Image.open(image_path)\n",
        "  image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "  # get embeddings\n",
        "  with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input)\n",
        "    text_features = model.encode_text(text_inputs)\n",
        "  # normalize\n",
        "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "  # get category probabilities\n",
        "  similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "  values, indices = similarity[0].topk(len(cats))\n",
        "  result.append({\n",
        "    \"file\": image_path,\n",
        "    \"pred\": [{\"label\": str(cats[int(index)]), \"prob\": float(value)} for value, index in zip(values, indices)]\n",
        "  })\n",
        "\n",
        "with open('/content/results.json', 'w') as out_file:\n",
        "     json.dump(result, out_file, indent = 4, ensure_ascii = False)\n"
      ],
      "metadata": {
        "id": "RKNz-GFHYcrn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}